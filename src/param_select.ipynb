{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('data/data.txt').astype(int)\n",
    "movies = np.genfromtxt('data/movies.txt', delimiter='\\t', dtype=None,encoding=None, \n",
    "                       names=['Movie ID','Title','Unknown','Action','Adventure','Animation','Childrens','Comedy','Crime',\n",
    "                             'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi',\n",
    "                              'Thriller','War','Western'], deletechars='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Factorization Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorizing with plain model.\n",
      "Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.01\n",
      "('Error:', 0.5180921475496216)\n",
      "('Added!', 0)\n",
      "('Error:', 0.3989173858254322)\n",
      "('Added!', 1)\n",
      "('Error:', 0.35409415536851546)\n",
      "('Added!', 2)\n",
      "('Error:', 0.3262124255733348)\n",
      "('Added!', 3)\n",
      "('Error:', 0.303014249709784)\n",
      "('Added!', 4)\n",
      "('Error:', 0.28545023955273585)\n",
      "('Added!', 5)\n",
      "('Error:', 0.2723045809760114)\n",
      "('Added!', 6)\n",
      "('Error:', 0.2588631499175684)\n",
      "('Added!', 7)\n",
      "('Error:', 0.2515403640907767)\n",
      "('Added!', 8)\n",
      "('Error:', 0.2403697837906989)\n",
      "('Added!', 9)\n",
      "('Error:', 0.23469271656679674)\n",
      "('Added!', 10)\n",
      "('Error:', 0.22953856817582943)\n",
      "('Added!', 11)\n",
      "('Error:', 0.22602968247358912)\n",
      "('Added!', 12)\n",
      "('Error:', 0.22454977988226418)\n",
      "('Added!', 13)\n",
      "('Error:', 0.21609722270465842)\n",
      "('Added!', 14)\n",
      "('Error:', 0.2157399220991249)\n",
      "('Stopped!', 15)\n",
      "Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.1\n",
      "('Error:', 0.5093922872607904)\n",
      "('Added!', 0)\n",
      "('Error:', 0.4350846031441088)\n",
      "('Added!', 1)\n",
      "('Error:', 0.40504570541521173)\n",
      "('Added!', 2)\n",
      "('Error:', 0.391555683011769)\n",
      "('Added!', 3)\n",
      "('Error:', 0.3734678263003498)\n",
      "('Added!', 4)\n",
      "('Error:', 0.3662448227057024)\n",
      "('Added!', 5)\n",
      "('Error:', 0.3556197480832407)\n",
      "('Added!', 6)\n",
      "('Error:', 0.3471188534098117)\n",
      "('Added!', 7)\n",
      "('Error:', 0.33936533058440144)\n",
      "('Added!', 8)\n",
      "('Error:', 0.3369849973778498)\n",
      "('Added!', 9)\n",
      "('Error:', 0.3310780486471739)\n",
      "('Added!', 10)\n",
      "('Error:', 0.32635529217532466)\n",
      "('Added!', 11)\n",
      "('Error:', 0.31969931021324216)\n",
      "('Added!', 12)\n",
      "('Error:', 0.316809856846)\n",
      "('Added!', 13)\n",
      "('Error:', 0.31258170745773206)\n",
      "('Added!', 14)\n",
      "('Error:', 0.30894190648472614)\n",
      "('Added!', 15)\n",
      "('Error:', 0.3064065294374521)\n",
      "('Added!', 16)\n",
      "('Error:', 0.30703967124506637)\n",
      "('Stopped!', 17)\n",
      "Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.2\n",
      "('Error:', 0.5415732796644505)\n",
      "('Added!', 0)\n",
      "('Error:', 0.4785490048372192)\n",
      "('Added!', 1)\n",
      "('Error:', 0.465837917363503)\n",
      "('Added!', 2)\n",
      "('Error:', 0.4587186023836993)\n",
      "('Added!', 3)\n",
      "('Error:', 0.4556198709256546)\n",
      "('Added!', 4)\n",
      "('Error:', 0.4540512645012898)\n",
      "('Added!', 5)\n",
      "('Error:', 0.45132211047970106)\n",
      "('Added!', 6)\n",
      "('Error:', 0.4459399925887726)\n",
      "('Added!', 7)\n",
      "('Error:', 0.4419448422380568)\n",
      "('Added!', 8)\n",
      "('Error:', 0.4465882917992495)\n",
      "('Added!', 9)\n",
      "('Error:', 0.44420375468172085)\n",
      "('Added!', 10)\n",
      "('Error:', 0.43908665426917487)\n",
      "('Added!', 11)\n",
      "('Error:', 0.4410538772172744)\n",
      "('Added!', 12)\n",
      "('Error:', 0.4433187536879655)\n",
      "('Added!', 13)\n",
      "('Error:', 0.4401373979602055)\n",
      "('Added!', 14)\n",
      "('Error:', 0.4376739648700282)\n",
      "('Added!', 15)\n",
      "('Error:', 0.4341672060579207)\n",
      "('Added!', 16)\n",
      "('Error:', 0.4323802691778248)\n",
      "('Added!', 17)\n",
      "('Error:', 0.43119084018921067)\n",
      "('Added!', 18)\n",
      "('Error:', 0.43620352097824205)\n",
      "('Added!', 19)\n",
      "('Error:', 0.4297440806446108)\n",
      "('Added!', 20)\n",
      "('Error:', 0.4354005989014553)\n",
      "('Added!', 21)\n",
      "('Error:', 0.4351099448969777)\n",
      "('Stopped!', 22)\n",
      "Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.5\n",
      "('Error:', 0.6830026245933012)\n",
      "('Added!', 0)\n",
      "('Error:', 0.6153749338167092)\n",
      "('Added!', 1)\n",
      "('Error:', 0.607329365513849)\n",
      "('Added!', 2)\n",
      "('Error:', 0.5970205617282887)\n",
      "('Added!', 3)\n",
      "('Error:', 0.5913843992145604)\n",
      "('Added!', 4)\n",
      "('Error:', 0.6003263915637626)\n",
      "('Added!', 5)\n",
      "('Error:', 0.6042277630114821)\n",
      "('Added!', 6)\n",
      "('Error:', 0.602425841528195)\n",
      "('Added!', 7)\n",
      "('Error:', 0.5911450341858497)\n",
      "('Added!', 8)\n",
      "('Error:', 0.5899202185853631)\n",
      "('Added!', 9)\n",
      "('Error:', 0.5883202021689576)\n",
      "('Added!', 10)\n",
      "('Error:', 0.6043557155302043)\n",
      "('Added!', 11)\n",
      "('Error:', 0.5871882657606039)\n",
      "('Added!', 12)\n",
      "('Error:', 0.6015930036487216)\n",
      "('Added!', 13)\n",
      "('Error:', 0.6034559487376691)\n",
      "('Added!', 14)\n",
      "('Error:', 0.5901761032577661)\n",
      "('Added!', 15)\n",
      "('Error:', 0.5983297852538958)\n",
      "('Added!', 16)\n",
      "('Error:', 0.6021198891324918)\n",
      "('Added!', 17)\n",
      "('Error:', 0.5984009877918265)\n",
      "('Added!', 18)\n",
      "('Error:', 0.5953047930155002)\n",
      "('Added!', 19)\n",
      "('Error:', 0.589326580612656)\n",
      "('Added!', 20)\n",
      "('Error:', 0.5993123010969096)\n",
      "('Added!', 21)\n",
      "('Error:', 0.5912801363244855)\n",
      "('Added!', 22)\n",
      "('Error:', 0.5935276496484604)\n",
      "('Added!', 23)\n",
      "('Error:', 0.5997440315382333)\n",
      "('Added!', 24)\n",
      "('Error:', 0.5927903394070191)\n",
      "('Added!', 25)\n",
      "('Error:', 0.5931357937763747)\n",
      "('Stopped!', 26)\n",
      "Printed figures!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7420380f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choice of optimizer: 'plain', 'bias' or 'oos'\n",
    "optimization = 'plain'\n",
    "\n",
    "Y_train = np.loadtxt('data/train.txt').astype(int)\n",
    "Y_test = np.loadtxt('data/test.txt').astype(int)\n",
    "\n",
    "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
    "N = movies.shape[0] # movies\n",
    "    \n",
    "if optimization == 'plain':\n",
    "    from collab_0 import train_model, get_err\n",
    "\n",
    "    print('Factorizing with plain model.')\n",
    "\n",
    "    regs = [1e-2, 1e-1, 0.2, 0.5]\n",
    "    eta = 0.03 # learning rate\n",
    "    # Epochs to plot learning curve\n",
    "    checkpoints = np.arange(40)\n",
    "    \n",
    "    K = 20\n",
    "    E_ins = []\n",
    "    E_outs = []\n",
    "    epochs = []\n",
    "    \n",
    "    for reg in regs:\n",
    "        E_in_reg = []\n",
    "        E_out_reg = []\n",
    "        print(\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s\" % (M, N, K, eta, reg))\n",
    "        Us, Vs, epochs_reg = train_model(M, N, K, eta, reg, Y_train, checkpoints=checkpoints)\n",
    "        # Compute insample and out of sample errors\n",
    "        for idx in range(len(Us)):\n",
    "            E_in_reg.append(get_err(Us[idx], Vs[idx], Y_train))\n",
    "            E_out_reg.append(get_err(Us[idx], Vs[idx], Y_test))\n",
    "        E_ins.append(E_in_reg)\n",
    "        E_outs.append(E_out_reg)\n",
    "        epochs.append(epochs_reg)\n",
    "    \n",
    "    # Plot E_ins\n",
    "    for i in range(len(regs)):\n",
    "        plt.plot(epochs[i], E_ins[i], label='$E_{in}, \\lambda=$'+str(regs[i]))\n",
    "    plt.title('$E_{in}$ learning curve')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.savefig('figs/plain_E_in.png')\n",
    "    plt.clf()\n",
    "    \n",
    "    # Plot E_outs\n",
    "    for i in range(len(regs)):\n",
    "        plt.plot(epochs[i], E_outs[i], label='$E_{out}, \\lambda=$'+str(regs[i]))\n",
    "    plt.title('$E_{out}$ learning curve')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.savefig('figs/plain_E_out.png')\n",
    "    plt.clf()\n",
    "    print('Printed figures!')\n",
    "    \n",
    "    \n",
    "elif optimization == 'bias':\n",
    "    from collab_bias import train_model, get_err\n",
    "\n",
    "    print('Factorizing with bias model.')\n",
    "\n",
    "    reg = 0.1\n",
    "    eta = 0.03 # learning rate\n",
    "    K = 20\n",
    "\n",
    "    print(\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s\"%(M, N, K, eta, reg))\n",
    "    U, V, a, b, err_train = train_model(M, N, K, eta, reg, Y_train)\n",
    "    print('Factorization complete.')\n",
    "    \n",
    "elif optimization == 'oos':\n",
    "    # oos model using https://github.com/benfred/implicit\n",
    "    \"\"\"\n",
    "    import implicit\n",
    "    from scipy import sparse\n",
    "    \n",
    "    print('Factorizing with off-the-shelf model.')\n",
    "    \n",
    "    m = sparse.coo_matrix((Y_train[:,2].astype(np.float32),\n",
    "                    (Y_train[:,1], Y_train[:,0])))\n",
    "    \n",
    "    model = implicit.als.AlternatingLeastSquares(factors=20)\n",
    "    model.fit(m.tocsr())\n",
    "    \n",
    "    V = model.item_factors\n",
    "    print('Factorization complete.')\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # oos model using http://surprise.readthedocs.io/en/stable/matrix_factorization.html\n",
    "    from surprise.prediction_algorithms.matrix_factorization import NMF\n",
    "    from surprise import Dataset\n",
    "    from surprise import Reader\n",
    "    from surprise import accuracy\n",
    "    \n",
    "    reader = Reader(line_format='user item rating', sep='\\t')\n",
    "    model = NMF(n_factors=20)\n",
    "    surprise_train = Dataset.load_from_file('data/data.txt', reader=reader)\n",
    "    #surprise_test = Dataset.load_from_file('data/test.txt', reader=reader)\n",
    "    model.fit(surprise_train.build_full_trainset())\n",
    "    #predictions = model.test(surprise_test.build_full_trainset().build_testset())\n",
    "    #err_test = accuracy.rmse(predictions)**2\n",
    "    V = model.qi\n",
    "    #print('Test error: %f' % err_test)\n",
    "    \n",
    "else:\n",
    "    print('Invalid optimization method specified')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'V' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-af688aeda998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'V' is not defined"
     ]
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD and Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'V' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-445617e6316c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Following convention in the guide where V is KxN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mV_centered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_centered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mVT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV_centered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'V' is not defined"
     ]
    }
   ],
   "source": [
    "# number of movies to visualize\n",
    "nmovies = 10\n",
    "\n",
    "# Perform the SVD\n",
    "\n",
    "# Following convention in the guide where V is KxN\n",
    "V_centered = (V-np.tile(np.mean(V,axis=1),(V.shape[1],1)).T).T\n",
    "u,s,vh = np.linalg.svd(V_centered, full_matrices=False)\n",
    "VT = np.dot(u[:,0:2].T,V_centered)\n",
    "\n",
    "# Normalize data for the plots\n",
    "VT[0] = (VT[0] - np.mean(VT[0]))/np.std(VT[0])\n",
    "VT[1] = (VT[1] - np.mean(VT[1]))/np.std(VT[1])\n",
    "\n",
    "# Find the data range for the plots\n",
    "ylim = [min(VT[1,:]),max(VT[1,:])]\n",
    "xlim = [min(VT[0,:]),max(VT[0,:])]\n",
    "\n",
    "## Popular movies\n",
    "r_counts = np.bincount(data[:,1])\n",
    "pop_inds_mov = np.argpartition(r_counts,-nmovies)[-nmovies:]+1\n",
    "inds = pop_inds_mov[:nmovies]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(14,8))\n",
    "ax.scatter(VT[0,inds],VT[1,inds])\n",
    "plt.title('Principal components of the %i most popular movies' % nmovies);\n",
    "plt.xlabel('PC1');\n",
    "plt.ylabel('PC2');\n",
    "plt.ylim(ylim)\n",
    "plt.xlim(xlim)\n",
    "\n",
    "xrange = max(VT[0,inds])-min(VT[0,inds])\n",
    "yrange = max(VT[1,inds])-min(VT[1,inds])\n",
    "    \n",
    "for j in inds:\n",
    "    # Make titles consistent wrt \"\n",
    "    mtitle = movies[j][1].replace('\"', '')[:-7]\n",
    "    # Make the titles more readable\n",
    "    if mtitle[-5:] == ', The':\n",
    "        mtitle = 'The ' + mtitle[:-5]\n",
    "    if mtitle[-3:] == ', A':\n",
    "        mtitle = 'A ' + mtitle[:-3]\n",
    "    ax.annotate(mtitle,(VT[0,j]+0.015*xrange,VT[1,j]-0.008*yrange))\n",
    "        \n",
    "\n",
    "## Movies by genre\n",
    "genres = ['Action','Adventure','Animation','Childrens','Comedy','Crime',\n",
    "                             'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi',\n",
    "                              'Thriller','War','Western']\n",
    "\n",
    "for idx,val in enumerate(genres):\n",
    "    g_inds_mov = np.array(np.where(movies[val]==1))[0]\n",
    "    inds = g_inds_mov[:nmovies]\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(14,8))\n",
    "    ax.scatter(VT[0,inds],VT[1,inds])\n",
    "    plt.title('Principal components of %i movies in \\'%s\\' genre' % (nmovies,val));\n",
    "    plt.xlabel('PC1');\n",
    "    plt.ylabel('PC2');\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlim(xlim)\n",
    "    \n",
    "    xrange = max(VT[0,inds])-min(VT[0,inds])\n",
    "    yrange = max(VT[1,inds])-min(VT[1,inds])\n",
    "\n",
    "    for j in inds:\n",
    "        # Make titles consistent wrt \"\n",
    "        mtitle = movies[j][1].replace('\"', '')[:-7]\n",
    "        # Make the titles more readable\n",
    "        if mtitle[-5:] == ', The':\n",
    "            mtitle = 'The ' + mtitle[:-5]\n",
    "        if mtitle[-3:] == ', A':\n",
    "            mtitle = 'A ' + mtitle[:-3]\n",
    "        ax.annotate(mtitle,(VT[0,j]+0.015*xrange,VT[1,j]-0.008*yrange))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
