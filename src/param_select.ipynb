{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('data/data.txt').astype(int)\n",
    "movies = np.genfromtxt('data/movies.txt', delimiter='\\t', dtype=None,encoding=None, \n",
    "                       names=['Movie ID','Title','Unknown','Action','Adventure','Animation','Childrens','Comedy','Crime',\n",
    "                             'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi',\n",
    "                              'Thriller','War','Western'], deletechars='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Factorization Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorizing with bias model.\n",
      "Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.01\n",
      "Epoch number 0\n",
      "Reg error 0.47005408803146703\n",
      "Epoch number 1\n",
      "Reg error 0.37199389151402884\n",
      "Epoch number 2\n",
      "Reg error 0.322357872414126\n",
      "Epoch number 3\n",
      "Reg error 0.28998044949431656\n",
      "Epoch number 4\n",
      "Reg error 0.266214949218063\n",
      "Epoch number 5\n",
      "Reg error 0.24819987902704488\n",
      "Epoch number 6\n",
      "Reg error 0.23504006496831378\n",
      "Epoch number 7\n",
      "Reg error 0.2237100966202676\n",
      "Epoch number 8\n",
      "Reg error 0.2145614087460248\n",
      "Epoch number 9\n",
      "Reg error 0.20750499333102787\n",
      "Epoch number 10\n",
      "Reg error 0.20072110926176262\n",
      "Epoch number 11\n",
      "Reg error 0.195744470682284\n",
      "Epoch number 12\n",
      "Reg error 0.19116753298969275\n",
      "Epoch number 13\n",
      "Reg error 0.187089307299923\n",
      "Epoch number 14\n",
      "Reg error 0.18338682316655916\n",
      "Epoch number 15\n",
      "Reg error 0.18017479837369527\n",
      "Epoch number 16\n",
      "Reg error 0.17764348139816713\n",
      "Epoch number 17\n",
      "Reg error 0.17538562275000383\n",
      "Epoch number 18\n",
      "Reg error 0.1733430679547099\n",
      "Epoch number 19\n",
      "Reg error 0.17103193681441875\n",
      "Epoch number 20\n",
      "Reg error 0.16959182252022714\n",
      "Epoch number 21\n",
      "Reg error 0.1677593348284747\n",
      "Epoch number 22\n",
      "Reg error 0.1664584169784143\n",
      "Epoch number 23\n",
      "Reg error 0.16497490759537725\n",
      "Epoch number 24\n",
      "Reg error 0.16332408058284964\n",
      "Epoch number 25\n",
      "Reg error 0.16251453462452325\n",
      "Epoch number 26\n",
      "Reg error 0.16100243487013044\n",
      "Epoch number 27\n",
      "Reg error 0.16013141092281477\n",
      "Epoch number 28\n",
      "Reg error 0.15908776956987514\n",
      "Epoch number 29\n",
      "Reg error 0.15815839741973245\n",
      "Epoch number 30\n",
      "Reg error 0.1572368680299909\n",
      "Epoch number 31\n",
      "Reg error 0.1560752793031227\n",
      "Epoch number 32\n",
      "Reg error 0.15539863064329643\n",
      "Epoch number 33\n",
      "Reg error 0.15464605491639766\n",
      "Epoch number 34\n",
      "Reg error 0.15424974889167922\n",
      "Trained!\n",
      "Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.05\n",
      "Epoch number 0\n",
      "Reg error 0.4713785668036463\n",
      "Epoch number 1\n",
      "Reg error 0.3865622596008728\n",
      "Epoch number 2\n",
      "Reg error 0.3467361004058606\n",
      "Epoch number 3\n",
      "Reg error 0.31883593639672914\n",
      "Epoch number 4\n",
      "Reg error 0.2972463227795036\n",
      "Epoch number 5\n",
      "Reg error 0.2791728963510076\n",
      "Epoch number 6\n",
      "Reg error 0.2651412769149887\n",
      "Epoch number 7\n",
      "Reg error 0.2531576451530943\n",
      "Epoch number 8\n",
      "Reg error 0.24375582664766662\n",
      "Epoch number 9\n",
      "Reg error 0.23555167782141975\n",
      "Epoch number 10\n",
      "Reg error 0.22884078145767145\n",
      "Epoch number 11\n",
      "Reg error 0.22317323713906526\n",
      "Epoch number 12\n",
      "Reg error 0.21891040665615\n",
      "Epoch number 13\n",
      "Reg error 0.21459084556533906\n",
      "Epoch number 14\n",
      "Reg error 0.21061009448026052\n",
      "Epoch number 15\n",
      "Reg error 0.20728622846875105\n",
      "Epoch number 16\n",
      "Reg error 0.2049216159311881\n",
      "Epoch number 17\n",
      "Reg error 0.20222167737557603\n",
      "Epoch number 18\n",
      "Reg error 0.20014506494683507\n",
      "Epoch number 19\n",
      "Reg error 0.19766772119164702\n",
      "Epoch number 20\n",
      "Reg error 0.1962606912631974\n",
      "Epoch number 21\n",
      "Reg error 0.19499267073073756\n",
      "Epoch number 22\n",
      "Reg error 0.1934227816037902\n",
      "Epoch number 23\n",
      "Reg error 0.19183598323698606\n",
      "Epoch number 24\n",
      "Reg error 0.19121258048698406\n",
      "Trained!\n",
      "Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.1\n",
      "Epoch number 0\n",
      "Reg error 0.48011884322399606\n",
      "Epoch number 1\n",
      "Reg error 0.4086439622073936\n",
      "Epoch number 2\n",
      "Reg error 0.3824063936620049\n",
      "Epoch number 3\n",
      "Reg error 0.36355151943243924\n",
      "Epoch number 4\n",
      "Reg error 0.34961814218394294\n",
      "Epoch number 5\n",
      "Reg error 0.33782462427517196\n",
      "Epoch number 6\n",
      "Reg error 0.3270412062403057\n",
      "Epoch number 7\n",
      "Reg error 0.3188991964796091\n",
      "Epoch number 8\n",
      "Reg error 0.3114427425103829\n",
      "Epoch number 9\n",
      "Reg error 0.304220581942479\n",
      "Epoch number 10\n",
      "Reg error 0.2984008922431748\n",
      "Epoch number 11\n",
      "Reg error 0.2933806167791508\n",
      "Epoch number 12\n",
      "Reg error 0.2881673747936173\n",
      "Epoch number 13\n",
      "Reg error 0.2841260426859147\n",
      "Epoch number 14\n",
      "Reg error 0.2809166829525759\n",
      "Epoch number 15\n",
      "Reg error 0.2779536581004083\n",
      "Epoch number 16\n",
      "Reg error 0.2744051523271554\n",
      "Epoch number 17\n",
      "Reg error 0.27201279112535176\n",
      "Epoch number 18\n",
      "Reg error 0.2694628615212043\n",
      "Epoch number 19\n",
      "Reg error 0.26739286644023286\n",
      "Epoch number 20\n",
      "Reg error 0.2650410104647787\n",
      "Epoch number 21\n",
      "Reg error 0.2641224854133258\n",
      "Epoch number 22\n",
      "Reg error 0.2626196245458884\n",
      "Epoch number 23\n",
      "Reg error 0.26199721940791454\n",
      "Trained!\n",
      "Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.2\n",
      "Epoch number 0\n",
      "Reg error 0.495225060702626\n",
      "Epoch number 1\n",
      "Reg error 0.4384114906472583\n",
      "Epoch number 2\n",
      "Reg error 0.4231791691365892\n",
      "Epoch number 3\n",
      "Reg error 0.4162707534127956\n",
      "Epoch number 4\n",
      "Reg error 0.41352402535648053\n",
      "Epoch number 5\n",
      "Reg error 0.41074900189948355\n",
      "Epoch number 6\n",
      "Reg error 0.40903882125655916\n",
      "Epoch number 7\n",
      "Reg error 0.4067407944173676\n",
      "Epoch number 8\n",
      "Reg error 0.4056743497426995\n",
      "Epoch number 9\n",
      "Reg error 0.4032926784762268\n",
      "Epoch number 10\n",
      "Reg error 0.40212282481484624\n",
      "Epoch number 11\n",
      "Reg error 0.40048380674785655\n",
      "Epoch number 12\n",
      "Reg error 0.3999871818704378\n",
      "Trained!\n",
      "Printed figures!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1185680f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choice of optimizer: 'plain', 'bias' or 'oos'\n",
    "optimization = 'bias'\n",
    "\n",
    "Y_train = np.loadtxt('data/train.txt').astype(int)\n",
    "Y_test = np.loadtxt('data/test.txt').astype(int)\n",
    "\n",
    "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
    "N = movies.shape[0] # movies\n",
    "    \n",
    "if optimization == 'plain':\n",
    "    from collab_0 import train_model, get_err\n",
    "\n",
    "    print('Factorizing with plain model.')\n",
    "\n",
    "    regs = [1e-2, 1e-1, 0.2, 0.5]\n",
    "    eta = 0.03 # learning rate\n",
    "    # Epochs to plot learning curve\n",
    "    checkpoints = np.arange(40)\n",
    "    \n",
    "    K = 20\n",
    "    E_ins = []\n",
    "    E_outs = []\n",
    "    epochs = []\n",
    "    \n",
    "    for reg in regs:\n",
    "        E_in_reg = []\n",
    "        E_out_reg = []\n",
    "        print(\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s\" % (M, N, K, eta, reg))\n",
    "        Us, Vs, epochs_reg = train_model(M, N, K, eta, reg, Y_train, checkpoints=checkpoints)\n",
    "        print(\"Trained!\")\n",
    "        # Compute insample and out of sample errors\n",
    "        for idx in range(len(Us)):\n",
    "            E_in_reg.append(get_err(Us[idx], Vs[idx], Y_train))\n",
    "            E_out_reg.append(get_err(Us[idx], Vs[idx], Y_test))\n",
    "        E_ins.append(E_in_reg)\n",
    "        E_outs.append(E_out_reg)\n",
    "        epochs.append(epochs_reg)\n",
    "    \n",
    "    # Plot E_ins\n",
    "    for i in range(len(regs)):\n",
    "        plt.plot(epochs[i], E_ins[i], label='$E_{in}, \\lambda=$'+str(regs[i]))\n",
    "    plt.title('$E_{in}$ learning curve')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.savefig('figs/plain_E_in.png')\n",
    "    plt.clf()\n",
    "    \n",
    "    # Plot E_outs\n",
    "    for i in range(len(regs)):\n",
    "        plt.plot(epochs[i], E_outs[i], label='$E_{out}, \\lambda=$'+str(regs[i]))\n",
    "    plt.title('$E_{out}$ learning curve')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.savefig('figs/plain_E_out.png')\n",
    "    plt.clf()\n",
    "    print('Printed figures!')\n",
    "    \n",
    "    \n",
    "elif optimization == 'bias':\n",
    "    from collab_bias import train_model, get_err\n",
    "    \n",
    "    print('Factorizing with bias model.')\n",
    "\n",
    "    regs = [1e-2, 0.05, 1e-1, 0.2]\n",
    "    eta = 0.03 # learning rate\n",
    "    K = 20\n",
    "    \n",
    "    # Epochs to plot learning curve\n",
    "    checkpoints = np.arange(40)\n",
    "    \n",
    "    E_ins = []\n",
    "    E_outs = []\n",
    "    epochs = []\n",
    "    \n",
    "    for reg in regs:\n",
    "        E_in_reg = []\n",
    "        E_out_reg = []\n",
    "        print(\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s\"%(M, N, K, eta, reg))\n",
    "        Us, Vs, As, Bs, epochs_reg = train_model(M, N, K, eta, reg, Y_train, checkpoints=checkpoints)\n",
    "        print(\"Trained!\")\n",
    "        # Compute insample and out of sample errors\n",
    "        for idx in range(len(Us)):\n",
    "            E_in_reg.append(get_err(Us[idx], Vs[idx], As[idx], Bs[idx], Y_train))\n",
    "            E_out_reg.append(get_err(Us[idx], Vs[idx], As[idx], Bs[idx], Y_test))\n",
    "        E_ins.append(E_in_reg)\n",
    "        E_outs.append(E_out_reg)\n",
    "        epochs.append(epochs_reg)\n",
    "    \n",
    "    # Plot E_ins\n",
    "    for i in range(len(regs)):\n",
    "        plt.plot(epochs[i], E_ins[i], label='$E_{in}, \\lambda=$'+str(regs[i]))\n",
    "    plt.title('$E_{in}$ learning curve')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.savefig('figs/bias_E_in.png')\n",
    "    plt.clf()\n",
    "    \n",
    "    # Plot E_outs\n",
    "    for i in range(len(regs)):\n",
    "        plt.plot(epochs[i], E_outs[i], label='$E_{out}, \\lambda=$'+str(regs[i]))\n",
    "    plt.title('$E_{out}$ learning curve')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.savefig('figs/bias_E_out.png')\n",
    "    plt.clf()\n",
    "    print('Printed figures!')\n",
    "    \n",
    "elif optimization == 'oos':\n",
    "    # oos model using https://github.com/benfred/implicit\n",
    "    \"\"\"\n",
    "    import implicit\n",
    "    from scipy import sparse\n",
    "    \n",
    "    print('Factorizing with off-the-shelf model.')\n",
    "    \n",
    "    m = sparse.coo_matrix((Y_train[:,2].astype(np.float32),\n",
    "                    (Y_train[:,1], Y_train[:,0])))\n",
    "    \n",
    "    model = implicit.als.AlternatingLeastSquares(factors=20)\n",
    "    model.fit(m.tocsr())\n",
    "    \n",
    "    V = model.item_factors\n",
    "    print('Factorization complete.')\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # oos model using http://surprise.readthedocs.io/en/stable/matrix_factorization.html\n",
    "    from surprise.prediction_algorithms.matrix_factorization import NMF\n",
    "    from surprise import Dataset\n",
    "    from surprise import Reader\n",
    "    from surprise import accuracy\n",
    "    \n",
    "    reader = Reader(line_format='user item rating', sep='\\t')\n",
    "    model = NMF(n_factors=20)\n",
    "    surprise_train = Dataset.load_from_file('data/data.txt', reader=reader)\n",
    "    #surprise_test = Dataset.load_from_file('data/test.txt', reader=reader)\n",
    "    model.fit(surprise_train.build_full_trainset())\n",
    "    #predictions = model.test(surprise_test.build_full_trainset().build_testset())\n",
    "    #err_test = accuracy.rmse(predictions)**2\n",
    "    V = model.qi\n",
    "    #print('Test error: %f' % err_test)\n",
    "    \n",
    "else:\n",
    "    print('Invalid optimization method specified')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD and Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'V' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-445617e6316c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Following convention in the guide where V is KxN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mV_centered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV_centered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mVT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV_centered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'V' is not defined"
     ]
    }
   ],
   "source": [
    "# number of movies to visualize\n",
    "nmovies = 10\n",
    "\n",
    "# Perform the SVD\n",
    "\n",
    "# Following convention in the guide where V is KxN\n",
    "V_centered = (V-np.tile(np.mean(V,axis=1),(V.shape[1],1)).T).T\n",
    "u,s,vh = np.linalg.svd(V_centered, full_matrices=False)\n",
    "VT = np.dot(u[:,0:2].T,V_centered)\n",
    "\n",
    "# Normalize data for the plots\n",
    "VT[0] = (VT[0] - np.mean(VT[0]))/np.std(VT[0])\n",
    "VT[1] = (VT[1] - np.mean(VT[1]))/np.std(VT[1])\n",
    "\n",
    "# Find the data range for the plots\n",
    "ylim = [min(VT[1,:]),max(VT[1,:])]\n",
    "xlim = [min(VT[0,:]),max(VT[0,:])]\n",
    "\n",
    "## Popular movies\n",
    "r_counts = np.bincount(data[:,1])\n",
    "pop_inds_mov = np.argpartition(r_counts,-nmovies)[-nmovies:]+1\n",
    "inds = pop_inds_mov[:nmovies]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(14,8))\n",
    "ax.scatter(VT[0,inds],VT[1,inds])\n",
    "plt.title('Principal components of the %i most popular movies' % nmovies);\n",
    "plt.xlabel('PC1');\n",
    "plt.ylabel('PC2');\n",
    "plt.ylim(ylim)\n",
    "plt.xlim(xlim)\n",
    "\n",
    "xrange = max(VT[0,inds])-min(VT[0,inds])\n",
    "yrange = max(VT[1,inds])-min(VT[1,inds])\n",
    "    \n",
    "for j in inds:\n",
    "    # Make titles consistent wrt \"\n",
    "    mtitle = movies[j][1].replace('\"', '')[:-7]\n",
    "    # Make the titles more readable\n",
    "    if mtitle[-5:] == ', The':\n",
    "        mtitle = 'The ' + mtitle[:-5]\n",
    "    if mtitle[-3:] == ', A':\n",
    "        mtitle = 'A ' + mtitle[:-3]\n",
    "    ax.annotate(mtitle,(VT[0,j]+0.015*xrange,VT[1,j]-0.008*yrange))\n",
    "        \n",
    "\n",
    "## Movies by genre\n",
    "genres = ['Action','Adventure','Animation','Childrens','Comedy','Crime',\n",
    "                             'Documentary','Drama','Fantasy','Film-Noir','Horror','Musical','Mystery','Romance','Sci-Fi',\n",
    "                              'Thriller','War','Western']\n",
    "\n",
    "for idx,val in enumerate(genres):\n",
    "    g_inds_mov = np.array(np.where(movies[val]==1))[0]\n",
    "    inds = g_inds_mov[:nmovies]\n",
    "\n",
    "    fig,ax = plt.subplots(figsize=(14,8))\n",
    "    ax.scatter(VT[0,inds],VT[1,inds])\n",
    "    plt.title('Principal components of %i movies in \\'%s\\' genre' % (nmovies,val));\n",
    "    plt.xlabel('PC1');\n",
    "    plt.ylabel('PC2');\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlim(xlim)\n",
    "    \n",
    "    xrange = max(VT[0,inds])-min(VT[0,inds])\n",
    "    yrange = max(VT[1,inds])-min(VT[1,inds])\n",
    "\n",
    "    for j in inds:\n",
    "        # Make titles consistent wrt \"\n",
    "        mtitle = movies[j][1].replace('\"', '')[:-7]\n",
    "        # Make the titles more readable\n",
    "        if mtitle[-5:] == ', The':\n",
    "            mtitle = 'The ' + mtitle[:-5]\n",
    "        if mtitle[-3:] == ', A':\n",
    "            mtitle = 'A ' + mtitle[:-3]\n",
    "        ax.annotate(mtitle,(VT[0,j]+0.015*xrange,VT[1,j]-0.008*yrange))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
